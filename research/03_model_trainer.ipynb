{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daed7a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Users\\user\\Python Programs\\Resume Projects\\End-to-End-Chicken-Disease-Classification\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\user\\Python Programs\\Resume Projects\\End-to-End-Chicken-Disease-Classification\")\n",
    "print(\"Current directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7309ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57bd2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir:Path\n",
    "    trianed_model_path:Path\n",
    "    updated_base_model:Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation:bool\n",
    "    params_image_size:list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "321dfd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnProject.constants import CONFIG_FILE_PATH,PARAMS_FILE_PATH\n",
    "from cnnProject.utils.common import readYamlFile,createDirectories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "949b05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_file_path=CONFIG_FILE_PATH,\n",
    "                 params_file_path=PARAMS_FILE_PATH):\n",
    "        self.config=readYamlFile(config_file_path)\n",
    "        self.params=readYamlFile(params_file_path)\n",
    "        createDirectories([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self)-> TrainingConfig:\n",
    "        training=self.config.training\n",
    "        prepare_base_model=self.config.prepare_base_model\n",
    "        params=self.params\n",
    "        training_data=os.path.join(self.config.data_ingestion.unzip_dir,\"Chicken-fecal-images\")\n",
    "        createDirectories([Path(training.root_dir)])\n",
    "\n",
    "        training_config=TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trianed_model_path=Path(training.trianed_model_path),\n",
    "            updated_base_model=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38e799df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74253404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self,config:TrainingConfig):\n",
    "        self.config=config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model=tf.keras.models.load_model(self.config.updated_base_model)\n",
    "    \n",
    "    #Imagine you're training a robot to identify fruit:\n",
    "        #ðŸ¥­ Train DataGenerator: You show it mangos in different lighting, angles, partially covered â€” so it learns to generalize.\n",
    "        #âœ… Validation DataGenerator: You show it clean, clear images of mangos â€” to check how well it learned.\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        datagenerator_kwargs=dict(rescale=1./255,validation_split=0.20)\n",
    "\n",
    "        dataflow_kwargs=dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator=tf.keras.preprocessing.image.ImageDataGenerator(**datagenerator_kwargs)\n",
    "\n",
    "        self.valid_generator=valid_datagenerator.flow_from_directory(directory=self.config.training_data,\n",
    "                                                                     subset=\"validation\",\n",
    "                                                                     shuffle=False,\n",
    "                                                                     **dataflow_kwargs)\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator=valid_datagenerator\n",
    "\n",
    "        self.train_generator=train_datagenerator.flow_from_directory(directory=self.config.training_data,\n",
    "                                                                     subset=\"training\",\n",
    "                                                                     shuffle=True,\n",
    "                                                                     **dataflow_kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(path:Path,model:tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    def train(self):\n",
    "        self.steps_per_epoch=self.train_generator.samples//self.train_generator.batch_size\n",
    "        self.validation_steps=self.valid_generator.samples//self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(self.train_generator,\n",
    "                       epochs=self.config.params_epochs,\n",
    "                       steps_per_epoch=self.steps_per_epoch,\n",
    "                       validation_steps=self.validation_steps,\n",
    "                       validation_data=self.valid_generator)\n",
    "        self.save_model(path=self.config.trianed_model_path,model=self.model)\n",
    "\n",
    "# ðŸ”§ 1. Configuration Setup\n",
    "# ðŸ”¹TrainingConfig dataclass holds all training-related parameters like:\n",
    "# \t\t->Paths to models and data\n",
    "# \t\t->Training hyperparameters (epochs, batch size, image size)\n",
    "# \t\t->Whether to apply data augmentation\n",
    "# ðŸ”¹ConfigurationManager class:\n",
    "# \t\t->Reads config.yaml and params.yaml\n",
    "# \t\t->Creates necessary directories\n",
    "# \t\t->Combines config and params to return a TrainingConfig object\n",
    "\n",
    "# ðŸ§  2. Training Class (Core Logic)\n",
    "# ðŸ”¹ __init__: Takes TrainingConfig and stores it\n",
    "# ðŸ”¹ get_base_model(): Loads a pre-trained model from the saved path (updated_base_model)\n",
    "# ðŸ”¹ train_valid_generator(): \n",
    "# \t\t->Creates training and validation image generators:\n",
    "# \t\t\tUses ImageDataGenerator with rescale=1./255 and validation_split=0.2\n",
    "# \t\t->Validation generator:\n",
    "# \t\t\tNo augmentation\n",
    "# \t\t\tUsed for evaluating model performance\n",
    "# \t\t->Training generator:\n",
    "# \t\t\tUses augmentation (flip, rotate, zoom, etc.) if enabled\n",
    "# \t\t\tHelps improve model generalization\n",
    "# ðŸ”¹ train():Calculates:\n",
    "# \t\t->steps_per_epoch = total training samples // batch size\n",
    "# \t\t->validation_steps = total validation samples // batch size\n",
    "# \t\t->Trains the model using .fit()\n",
    "# \t\t->Saves the trained model to the specified path using save_model()\n",
    "# ðŸ”¹ save_model(path, model): Static method to save the trained model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8fb842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-28 23:13:24,841 : INFO : common : the yaml file form the path config\\config.yaml loaded Sucessfully]\n",
      "[2025-06-28 23:13:24,842 : INFO : common : the yaml file form the path params.yaml loaded Sucessfully]\n",
      "[2025-06-28 23:13:24,843 : INFO : common : Directories created Sucessfully at artifacts]\n",
      "[2025-06-28 23:13:24,844 : INFO : common : Directories created Sucessfully at artifacts\\training]\n",
      "Found 78 images belonging to 2 classes.\n",
      "Found 312 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - 12s 612ms/step - loss: 13.7981 - accuracy: 0.5034 - val_loss: 26.5980 - val_accuracy: 0.3906\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 9.5160 - accuracy: 0.6047 - val_loss: 1.0265 - val_accuracy: 0.8594\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 11s 585ms/step - loss: 3.7275 - accuracy: 0.7534 - val_loss: 1.4284 - val_accuracy: 0.7969\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 11s 586ms/step - loss: 0.9659 - accuracy: 0.8615 - val_loss: 2.8915 - val_accuracy: 0.7344\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 11s 599ms/step - loss: 2.3348 - accuracy: 0.8289 - val_loss: 2.4344 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 11s 596ms/step - loss: 3.3256 - accuracy: 0.7872 - val_loss: 2.8534 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 11s 604ms/step - loss: 1.5360 - accuracy: 0.8615 - val_loss: 0.9578 - val_accuracy: 0.8906\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 11s 605ms/step - loss: 0.5460 - accuracy: 0.9223 - val_loss: 0.9517 - val_accuracy: 0.9219\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 11s 605ms/step - loss: 1.2553 - accuracy: 0.8885 - val_loss: 0.8518 - val_accuracy: 0.9219\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 11s 604ms/step - loss: 0.4582 - accuracy: 0.9358 - val_loss: 0.8244 - val_accuracy: 0.9219\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.2750 - accuracy: 0.9595 - val_loss: 0.9897 - val_accuracy: 0.8906\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 11s 619ms/step - loss: 0.3884 - accuracy: 0.9358 - val_loss: 0.8063 - val_accuracy: 0.9062\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 12s 608ms/step - loss: 1.5473 - accuracy: 0.8615 - val_loss: 1.1382 - val_accuracy: 0.8906\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.3177 - accuracy: 0.9527 - val_loss: 0.7414 - val_accuracy: 0.9219\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.3422 - accuracy: 0.9493 - val_loss: 0.7180 - val_accuracy: 0.9219\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 12s 610ms/step - loss: 0.4073 - accuracy: 0.9257 - val_loss: 1.2868 - val_accuracy: 0.8438\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 11s 606ms/step - loss: 1.4744 - accuracy: 0.8547 - val_loss: 0.7126 - val_accuracy: 0.9219\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 11s 605ms/step - loss: 0.5271 - accuracy: 0.9257 - val_loss: 1.1295 - val_accuracy: 0.8906\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 11s 606ms/step - loss: 0.5189 - accuracy: 0.9155 - val_loss: 1.2753 - val_accuracy: 0.8750\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 11s 605ms/step - loss: 1.0270 - accuracy: 0.8649 - val_loss: 0.8596 - val_accuracy: 0.9062\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 11s 618ms/step - loss: 0.6096 - accuracy: 0.9155 - val_loss: 3.7415 - val_accuracy: 0.7031\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 12s 618ms/step - loss: 1.3316 - accuracy: 0.8487 - val_loss: 0.7951 - val_accuracy: 0.9531\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 12s 619ms/step - loss: 0.3108 - accuracy: 0.9474 - val_loss: 0.7437 - val_accuracy: 0.9375\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 12s 609ms/step - loss: 0.3540 - accuracy: 0.9527 - val_loss: 0.7725 - val_accuracy: 0.9531\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 12s 609ms/step - loss: 0.4963 - accuracy: 0.9324 - val_loss: 0.8176 - val_accuracy: 0.9375\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.4052 - accuracy: 0.9324 - val_loss: 0.7000 - val_accuracy: 0.9531\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.2924 - accuracy: 0.9595 - val_loss: 0.7125 - val_accuracy: 0.9531\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.9398 - accuracy: 0.9054 - val_loss: 0.7494 - val_accuracy: 0.9219\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.2896 - accuracy: 0.9459 - val_loss: 0.7599 - val_accuracy: 0.9062\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 12s 608ms/step - loss: 0.6450 - accuracy: 0.9257 - val_loss: 0.7232 - val_accuracy: 0.9531\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 11s 606ms/step - loss: 0.3256 - accuracy: 0.9459 - val_loss: 2.9076 - val_accuracy: 0.7500\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.8726 - accuracy: 0.8953 - val_loss: 0.7836 - val_accuracy: 0.9375\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 12s 609ms/step - loss: 0.4724 - accuracy: 0.9426 - val_loss: 0.7817 - val_accuracy: 0.9375\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 12s 608ms/step - loss: 0.2929 - accuracy: 0.9459 - val_loss: 0.9605 - val_accuracy: 0.8906\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 11s 606ms/step - loss: 0.4395 - accuracy: 0.9189 - val_loss: 0.7322 - val_accuracy: 0.9375\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 11s 605ms/step - loss: 0.5618 - accuracy: 0.9257 - val_loss: 0.7936 - val_accuracy: 0.9375\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 12s 621ms/step - loss: 0.2688 - accuracy: 0.9527 - val_loss: 0.7051 - val_accuracy: 0.9531\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 12s 607ms/step - loss: 0.2278 - accuracy: 0.9662 - val_loss: 0.7303 - val_accuracy: 0.9531\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 12s 609ms/step - loss: 0.6906 - accuracy: 0.9122 - val_loss: 0.7838 - val_accuracy: 0.9375\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 12s 626ms/step - loss: 0.2707 - accuracy: 0.9493 - val_loss: 0.8968 - val_accuracy: 0.8906\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 12s 615ms/step - loss: 0.2346 - accuracy: 0.9595 - val_loss: 0.6562 - val_accuracy: 0.9531\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 12s 612ms/step - loss: 0.1940 - accuracy: 0.9730 - val_loss: 2.0760 - val_accuracy: 0.8438\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 12s 623ms/step - loss: 1.4585 - accuracy: 0.8750 - val_loss: 0.6979 - val_accuracy: 0.9219\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 12s 648ms/step - loss: 0.4142 - accuracy: 0.9527 - val_loss: 0.7086 - val_accuracy: 0.9531\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 12s 628ms/step - loss: 0.3378 - accuracy: 0.9561 - val_loss: 0.9606 - val_accuracy: 0.9062\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 12s 608ms/step - loss: 0.2343 - accuracy: 0.9628 - val_loss: 0.7642 - val_accuracy: 0.9375\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 11s 620ms/step - loss: 1.2364 - accuracy: 0.8885 - val_loss: 0.7668 - val_accuracy: 0.9375\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 12s 608ms/step - loss: 0.6033 - accuracy: 0.9358 - val_loss: 0.8847 - val_accuracy: 0.9062\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 11s 607ms/step - loss: 0.2401 - accuracy: 0.9561 - val_loss: 1.8824 - val_accuracy: 0.8594\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 11s 606ms/step - loss: 0.2958 - accuracy: 0.9493 - val_loss: 0.6503 - val_accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    training_config=config.get_training_config()\n",
    "    training=Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnnProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
